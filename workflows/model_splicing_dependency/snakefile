"""
Author: Miquel Anglada Girotto
Contact: miquelangladagirotto [at] gmail [dot] com
Last Update: 2021-01-12

Workflow purpose
--------------
Workflow to analyze putative associations between exons and cancer at single-exon level.


Outline
-------
        
"""

import os

# variables
ROOT = os.path.dirname(os.path.dirname(os.getcwd()))
RAW_DIR = os.path.join(ROOT,'data','raw')
PREP_DIR = os.path.join(ROOT,'data','prep')
RESULTS_DIR = os.path.join(ROOT,'results','model_splicing_dependency')
SRC_DIR = os.path.join(ROOT,'src')
SUPPORT_DIR = os.path.join(ROOT,'support')
TS_DIR = os.path.join(os.path.dirname(os.path.dirname(ROOT)),'repositories','target_spotter')


EVENT_TYPES = ["EX"] # ['EX','ALTA','ALTD','INT']
N_SAMPLES = {
    "Thomas2020": 2,
    "Hart2015": 12
}

# model selection parameters
THRESH_PVALUE = 0.025
THRESH_CORR = 0.2
THRESH_NOBS = 0
N_RANDOM_MODELS = 1000

##### RULES #####
rule all:
    input:
        # fit gene dependencies and get empirical distributions of coefficients
        expand(os.path.join(RESULTS_DIR,'files','models_gene_dependency-{event_type}'), event_type=EVENT_TYPES),
        
        # compute splicing dependencies (mean, median, std)
        expand(os.path.join(RESULTS_DIR,'files','splicing_dependency-{event_type}'), event_type=EVENT_TYPES),
        
        # summarize splicing dependencies by primary disease
        # expand(os.path.join(RESULTS_DIR,'files','splicing_dependency_summaries-{event_type}','{field}.tsv.gz'), field=["primary_disease"], event_type=EVENT_TYPES),
        
        # EDA models of splicing dependencies
        # os.path.join(RESULTS_DIR,'figures','model_selection'),
        
        # write selected models
        ## as lists
        expand(os.path.join(RESULTS_DIR,'files','selected_models-{event_type}.txt'), event_type=EVENT_TYPES),
        expand(os.path.join(RESULTS_DIR,'files','selected_models-{event_type}-genes.txt'), event_type=EVENT_TYPES),
        ## randomize model selection
        expand(os.path.join(RESULTS_DIR,'files','random_model_selection-{event_type}-{it}its','events'), event_type=EVENT_TYPES, it=N_RANDOM_MODELS),
        expand(os.path.join(RESULTS_DIR,'files','random_model_selection-{event_type}-{it}its','genes'), event_type=EVENT_TYPES, it=N_RANDOM_MODELS),
        expand(os.path.join(RESULTS_DIR,'files','random_model_selection-{event_type}-{it}its','events-merged.tsv.gz'), event_type=EVENT_TYPES, it=N_RANDOM_MODELS),
        expand(os.path.join(RESULTS_DIR,'files','random_model_selection-{event_type}-{it}its','genes-merged.tsv.gz'), event_type=EVENT_TYPES, it=N_RANDOM_MODELS),
        # impute splicing dependencies with selected models
        # expand(os.path.join(RESULTS_DIR,'files','imputed_splicing_dependency_mean-{event_type}.tsv.gz'), event_type=['EX']),
        
        # embed splicing dependencies with selected models
        # expand(os.path.join(RESULTS_DIR,'files','embedded_splicing_dependency_mean-{event_type}.tsv.gz'), event_type=['EX']),
        
        # EDA embeddings of splicing dependencies
        # os.path.join(RESULTS_DIR,'figures','splicing_dependency_embeddings'),
        
        # Associations
        expand(os.path.join(RESULTS_DIR,'files','correlation_spldep_indices-{event_type}.tsv.gz'), event_type=EVENT_TYPES),
        
        # ENCORE
        ## compute splicing dependencies
        expand(os.path.join(RESULTS_DIR,'files','ENCORE','splicing_dependency-{event_type}'), event_type=EVENT_TYPES),
        
        ## compute delta TPM
        os.path.join(RESULTS_DIR,'files','ENCORE','diff_tpm.tsv.gz'),
        
        ## compute delta PSI
        expand(os.path.join(RESULTS_DIR,'files','ENCORE','delta_psi-{event_type}.tsv.gz'), event_type=EVENT_TYPES),
        expand(os.path.join(RESULTS_DIR,'files','ENCORE','delta_psi_rel-{event_type}.tsv.gz'), event_type=EVENT_TYPES),
        
        ## compute delta Spl. Dep.
        expand(os.path.join(RESULTS_DIR,'files','ENCORE','delta_spldep-{event_type}.tsv.gz'), event_type=EVENT_TYPES),
        
        ## create ontology from KDs
        expand(os.path.join(RESULTS_DIR,'files','ENCORE','kd_gene_sets-{event_type}.tsv.gz'), event_type=EVENT_TYPES),
        
        # compute normalized splicing dependency (harm score)
        expand(os.path.join(RESULTS_DIR,'files','ENCORE','harm_score-{event_type}.tsv.gz'), event_type=EVENT_TYPES),
        expand(os.path.join(RESULTS_DIR,'files','ENCORE','harm_score_rel-{event_type}.tsv.gz'), event_type=EVENT_TYPES),
        
        # Exon CRISPR screen (Thomas 2020)
        ## compute splicing dependencies
        expand(os.path.join(RESULTS_DIR,'files','{dataset}','splicing_dependency-{event_type}'), event_type=EVENT_TYPES, dataset=["Thomas2020","Hart2015"]),
        
        # Achilles Gene dependencies
        expand(os.path.join(RESULTS_DIR,'files','achilles','models_gene_dependency-{event_type}'), event_type=EVENT_TYPES),
        
        # Shortest path length from selected genes to cancer-driver genes vs random selection
#         expand(os.path.join(RESULTS_DIR,'files','COSMIC','ppi_closeness-{event_type}','real.tsv.gz'), event_type=EVENT_TYPES),
#         expand(os.path.join(RESULTS_DIR,'files','COSMIC','ppi_closeness-{event_type}','random_it{it}.tsv.gz'), event_type=EVENT_TYPES, it=list(range(N_RANDOM_MODELS))),
#         expand(os.path.join(RESULTS_DIR,'files','COSMIC','ppi_closeness-{event_type}','merged.tsv.gz'), event_type=EVENT_TYPES)
        
        # Validation
        ## CRISPR event KO dataset (Thomas 2020)
        # os.path.join(RESULTS_DIR,'figures','validation_crispr'),
        ## EDA known genes of interest
        # os.path.join(RESULTS_DIR,'figures','validation_genes_oi'),
        
        # EDA relationship between interaction terms in linear models
        # os.path.join(RESULTS_DIR,'figures','interaction_analysis')
        
        
rule model_gene_dependency:
    input:
        splicing_file = os.path.join(PREP_DIR,'event_psi','CCLE-{event_type}.tsv.gz'),
        genexpr_file = os.path.join(PREP_DIR,'genexpr_tpm','CCLE.tsv.gz'),
        gene_dependency_file = os.path.join(PREP_DIR,'demeter2','CCLE.tsv.gz'),
        mapping_file = os.path.join(RAW_DIR,'VastDB','event_annotation-Hs2.tsv.gz')
    output:
        directory(os.path.join(RESULTS_DIR,'files','models_gene_dependency-{event_type}'))
    threads: 24
    resources:
        runtime = 3600*12, # 12h
        memory = 50
    params:
        script_dir = TS_DIR,
        n_iterations = 1000
    shell:
        """
        nice python {params.script_dir}/target_spotter spldep_fit \
                    --gene_dependency_file={input.gene_dependency_file} \
                    --splicing_file={input.splicing_file} \
                    --genexpr_file={input.genexpr_file} \
                    --mapping_file={input.mapping_file} \
                    --output_dir={output} \
                    --n_iterations={params.n_iterations} \
                    --n_jobs={threads} \
                    --log_transform
        """
        
        
rule compute_splicing_dependency:
    input:
        psi = os.path.join(PREP_DIR,'event_psi','CCLE-{event_type}.tsv.gz'),
        genexpr = os.path.join(PREP_DIR,'genexpr_tpm','CCLE.tsv.gz'),
        coefs_dir = os.path.join(RESULTS_DIR,'files','models_gene_dependency-{event_type}')
    output:
        directory(os.path.join(RESULTS_DIR,'files','splicing_dependency-{event_type}'))
    threads: 20
    resources:
        runtime = 86400, # seconds = 24h = 1 day
        memory = 30
    params:
        script_dir = TS_DIR
    shell:
        """
        nice python {params.script_dir}/target_spotter spldep_predict \
                    --splicing_file={input.psi} \
                    --genexpr_file={input.genexpr} \
                    --coefs_splicing_file={input.coefs_dir}/coefs_splicing.pickle.gz \
                    --coefs_genexpr_file={input.coefs_dir}/coefs_genexpr.pickle.gz \
                    --coefs_intercept_file={input.coefs_dir}/coefs_intercept.pickle.gz \
                    --output_dir={output} \
                    --n_jobs={threads} \
                    --log_transform
        """
        
    
rule list_selected_models:
    input:
        coefs_dir = os.path.join(RESULTS_DIR,'files','models_gene_dependency-{event_type}')
    output:
        selected_models = os.path.join(RESULTS_DIR,'files','selected_models-{event_type}.txt'),
        selected_models_gene = os.path.join(RESULTS_DIR,'files','selected_models-{event_type}-genes.txt')
    params:
        thresh_lr_pvalue = THRESH_PVALUE,
        thresh_corr = THRESH_CORR,
        thresh_nobs = THRESH_NOBS
    run:
        import os
        import pandas as pd
        
        models = pd.read_table(os.path.join(input.coefs_dir,'model_summaries.tsv.gz'))
        models = models.loc[
            (models['lr_pvalue']<params.thresh_lr_pvalue) &
            (models['pearson_correlation_mean']>params.thresh_corr) &
            (models['n_obs']>params.thresh_nobs)
        ].copy()
        
        models["EVENT"].to_csv(output.selected_models, sep="\t", header=None, index=False)
        models["GENE"].drop_duplicates().to_csv(output.selected_models_gene, sep="\t", header=None, index=False)

        
rule random_model_selection:
    input:
        coefs_dir = os.path.join(RESULTS_DIR,'files','models_gene_dependency-{event_type}')
    output:
        selected_events_dir = directory(os.path.join(RESULTS_DIR,'files','random_model_selection-{event_type}-{it}its','events')),
        selected_genes_dir = directory(os.path.join(RESULTS_DIR,'files','random_model_selection-{event_type}-{it}its','genes'))
    params:
        thresh_lr_pvalue = THRESH_PVALUE,
        thresh_corr = THRESH_CORR,
        thresh_nobs = THRESH_NOBS,
        n_random_it = N_RANDOM_MODELS
    run:
        import os
        import pandas as pd
        import numpy as np
        
        # get number of selected exon models
        models = pd.read_table(os.path.join(input.coefs_dir,'model_summaries.tsv.gz'))
        idx = ((models['lr_pvalue']<params.thresh_lr_pvalue) &
              (models['pearson_correlation_mean']>params.thresh_corr) &
              (models['n_obs']>params.thresh_nobs))
        n_selected = sum(idx)
        print("Selected %s models." % n_selected)
        
        # randomly select exon models and save them
        os.makedirs(output.selected_events_dir)
        os.makedirs(output.selected_genes_dir)

        for it in np.arange(params.n_random_it):
            #print(it)
            
            np.random.seed(it) # ensure reproducibility
            
            # select randomly 
            random_events = np.random.choice(models["EVENT"], size=n_selected, replace=False)
            tmp_models = models.loc[models["EVENT"].isin(random_events)].copy()
            
            # save
            tmp_models["EVENT"].to_csv(os.path.join(output.selected_events_dir,str(it)+".txt"), sep="\t", header=None, index=False)
            tmp_models["GENE"].drop_duplicates().to_csv(os.path.join(output.selected_genes_dir,str(it)+".txt"), sep="\t", header=None, index=False)
            
        print("Done!")

        
        
rule combine_randomly_selected_models:
    input:
        random_events_dir = os.path.join(RESULTS_DIR,'files','random_model_selection-{event_type}-{it}its','events'),
        random_genes_dir = os.path.join(RESULTS_DIR,'files','random_model_selection-{event_type}-{it}its','genes')
    output:
        random_events = os.path.join(RESULTS_DIR,'files','random_model_selection-{event_type}-{it}its','events-merged.tsv.gz'),
        random_genes = os.path.join(RESULTS_DIR,'files','random_model_selection-{event_type}-{it}its','genes-merged.tsv.gz')
    params:
        n_random_it = N_RANDOM_MODELS
    run:
        import os
        import pandas as pd
        
        random_events = []
        random_genes = []
        for it in range(params.n_random_it):
            print(it)
            
            # events
            f = os.path.join(input.random_events_dir,str(it)+".txt")
            events = pd.DataFrame({
                "random_iteration": "it"+str(it),
                "EVENT": pd.read_table(f, header=None)[0].to_list()
            })
            random_events.append(events)
            
            # genes
            f = os.path.join(input.random_genes_dir,str(it)+".txt")
            genes = pd.DataFrame({
                "random_iteration": "it"+str(it),
                "GENE": pd.read_table(f, header=None)[0].to_list()
            })
            random_genes.append(genes)
            
        random_events = pd.concat(random_events)
        random_genes = pd.concat(random_genes)
        
        random_events.to_csv(output.random_events, sep="\t", index=False, compression="gzip")
        random_genes.to_csv(output.random_genes, sep="\t", index=False, compression="gzip")
        
        print("Done!")
        
        
rule summarize_splicing_dependency_by_field:
    input:
        spldep_dir = os.path.join(RESULTS_DIR,'files','splicing_dependency-{event_type}').format(event_type='{event_type}'),
        metadata = os.path.join(PREP_DIR,'metadata','CCLE.tsv.gz'),
    output:
        os.path.join(RESULTS_DIR,'files','splicing_dependency_summaries-{event_type}','{field}.tsv.gz')
    params:
        field = '{field}'
    run:
        import os
        import pandas as pd
        dfs = []
        spldep = pd.read_table(os.path.join(input.spldep_dir,'mean.tsv.gz'), index_col=0)
        metadata = pd.read_table(input.metadata)
            
        field_values = set(metadata[params.field].dropna().unique())
        for field_value in field_values:
            print(field_value)
            idx = (metadata[params.field]==field_value)
            samples_oi = metadata.loc[idx,"DepMap_ID"].values
            samples_oi = set(spldep.columns).intersection(samples_oi)

            df = pd.DataFrame({
                "EVENT": spldep.index,
                "mean": spldep[samples_oi].mean(axis=1),
                "median": spldep[samples_oi].median(axis=1),
                "std": spldep[samples_oi].std(axis=1),
                "q05": spldep[samples_oi].quantile(0.05, axis=1),
                "q95": spldep[samples_oi].quantile(0.95, axis=1),
                "nobs": len(samples_oi)
            })
            df[params.field] = field_value
            dfs.append(df)

            del df

        dfs = pd.concat(dfs)
        dfs.to_csv(output[0], sep="\t", index=False, compression="gzip")
        
    
rule impute_splicing_dependency:
    input:
        spldep_dir = os.path.join(RESULTS_DIR,'files','splicing_dependency-{event_type}'),
        rows_oi = os.path.join(RESULTS_DIR,'files','selected_models-{event_type}.txt')
    output:
        os.path.join(RESULTS_DIR,'files','imputed_splicing_dependency_mean-{event_type}.tsv.gz')
    params:
        script_dir=os.path.join(SRC_DIR,'python'),
        method = 'knn',
        method_kws = '\'{"n_neighbors":5}\'',
        features_as_rows = True
    shell:
        """
        python {params.script_dir}/impute_nan.py \
                    --input_file={params.spldep_dir}/mean.tsv.gz \
                    --output_file={output} \
                    --rows_oi_file={input.rows_oi} \
                    --method={params.method} \
                    --method_kws={params.method_kws} \
                    --features_as_rows={params.features_as_rows}
        """
        
        
rule embed_matrices:
    input:
        os.path.join(RESULTS_DIR,'files','imputed_splicing_dependency_mean-{event_type}.tsv.gz')
    output:
        os.path.join(RESULTS_DIR,'files','embedded_splicing_dependency_mean-{event_type}.tsv.gz')
    params:
        script_dir=os.path.join(SRC_DIR,'python')
    shell:
        """
        python {params.script_dir}/embed_and_cluster.py \
                    --matrix_file={input} \
                    --output_file={output} 
        """
        
        
rule figures_model_selection:
    input:
        models = os.path.join(RESULTS_DIR,'files','models_gene_dependency-EX','model_summaries.tsv.gz'),
        rnai = os.path.join(PREP_DIR,'demeter2','CCLE.tsv.gz'),
        spldep = os.path.join(RESULTS_DIR,'files','splicing_dependency-EX','mean.tsv.gz'),
        msigdb = os.path.join(RAW_DIR,'MSigDB','msigdb_v7.4','msigdb_v7.4_files_to_download_locally','msigdb_v7.4_GMTs'),
        protein_impact = os.path.join(RAW_DIR,'VastDB','PROT_IMPACT-hg38-v3.tab.gz'),
        gene_mut_freq = os.path.join(PREP_DIR,'gene_mutation_freq','CCLE.tsv.gz'),
        event_mut_freq = os.path.join(PREP_DIR,'event_mutation_freq','CCLE-EX.tsv.gz'),
        possible_interactions = os.path.join(SUPPORT_DIR,'possible_pairwise_interaction_categories.tsv'),
        cancer_events = os.path.join(SUPPORT_DIR,'cancer_events.tsv'),
        ccle_stats = os.path.join(PREP_DIR,'stats','CCLE.tsv.gz')
    output:
        directory(os.path.join(RESULTS_DIR,'figures','model_selection'))
    shell:
        """
        Rscript scripts/figures_model_selection.R \
                    --models_file={input.models} \
                    --ccle_stats_file={input.ccle_stats} \
                    --msigdb_dir={input.msigdb} \
                    --protein_impact_file={input.protein_impact} \
                    --gene_mut_freq_file={input.gene_mut_freq} \
                    --event_mut_freq_file={input.event_mut_freq} \
                    --cancer_events_file={input.cancer_events} \
                    --rnai_file={input.rnai} \
                    --spldep_file={input.spldep} \
                    --possible_interactions_file={input.possible_interactions} \
                    --figs_dir={output}
        """
    
    
rule figures_embeddings:
    input:
        embedded_dependency = os.path.join(RESULTS_DIR,'files','embedded_splicing_dependency_mean-EX.tsv.gz'),
        metadata = os.path.join(PREP_DIR,'metadata','CCLE.tsv.gz'),
        indices = os.path.join(PREP_DIR,'transcriptome_indices','CCLE.tsv.gz')
    output:
        directory(os.path.join(RESULTS_DIR,'figures','splicing_dependency_embeddings'))
    shell:
        """
        Rscript scripts/figures_embedding.R \
                    --embedded_dependency_file={input.embedded_dependency} \
                    --metadata_file={input.metadata} \
                    --indices_file={input.indices} \
                    --figs_dir={output}
        """
    

rule figures_validation_crispr:
    input:
        protein_impact = os.path.join(RAW_DIR,'VastDB','PROT_IMPACT-hg38-v3.tab.gz'),
        annotation = os.path.join(RAW_DIR,'VastDB','EVENT_INFO-hg38_noseqs.tsv'),
        psi = os.path.join(RAW_DIR,'articles','Thomas2020','vast_out','PSI-minN_1-minSD_0-noVLOW-min_ALT_use25-Tidy.tab.gz'),
        genexpr = os.path.join(RAW_DIR,'articles','Thomas2020','vast_out','TPM-hg38-2.tab.gz'),
        crispr_screen = os.path.join(PREP_DIR,'Thomas2020','crispr_screen.tsv.gz'),
        models = os.path.join(RESULTS_DIR,'files','models_gene_dependency-EX.tsv.gz')
    output:
        directory(os.path.join(RESULTS_DIR,'figures','validation_crispr'))
    params:
        total = 100
    shell:
        """
        Rscript scripts/figures_validation_crispr.R \
                    --protein_impact_file={input.protein_impact} \
                    --annotation_file={input.annotation} \
                    --psi_file={input.psi} \
                    --genexpr_file={input.genexpr} \
                    --crispr_screen_file={input.crispr_screen} \
                    --models_file={input.models} \
                    --figs_dir={output} \
                    --total={params.total}
        """
        
        
rule correlate_transcriptome_indices_ccle:
    input:
        spldep_dir = os.path.join(RESULTS_DIR,'files','splicing_dependency-{event_type}'),
        indices = os.path.join(PREP_DIR,'transcriptome_indices','CCLE.tsv.gz')
    output:
        os.path.join(RESULTS_DIR,'files','correlation_spldep_indices-{event_type}.tsv.gz')
    params:
        script_dir = os.path.join(SRC_DIR,'python'),
        sample_col = 'index',
        cor_method = 'spearman',
        padj_method = 'fdr_bh'
    shell:
        """
        nice python {params.script_dir}/correlation_exon_transcriptome_indices.py \
                        --omic_file={input.spldep_dir}/mean.tsv.gz \
                        --sample_properties_file={input.indices} \
                        --sample_col={params.sample_col} \
                        --cor_method={params.cor_method} \
                        --padj_method={params.padj_method} \
                        --output_file={output}
        """

        
rule compute_splicing_dependency_encore:
    input:
        psi = os.path.join(PREP_DIR,'event_psi','ENCORE-{event_type}.tsv.gz'),
        genexpr = os.path.join(PREP_DIR,'genexpr_tpm','ENCORE.tsv.gz'),
        coefs_dir = os.path.join(RESULTS_DIR,'files','models_gene_dependency-{event_type}')
    output:
        directory(os.path.join(RESULTS_DIR,'files','ENCORE','splicing_dependency-{event_type}'))
    threads: 15
    resources:
        runtime = 86400, # seconds = 24h = 1 day
        memory = 30
    params:
        script_dir = TS_DIR
    shell:
        """
        nice python {params.script_dir}/target_spotter spldep_predict \
                    --splicing_file={input.psi} \
                    --genexpr_file={input.genexpr} \
                    --coefs_splicing_file={input.coefs_dir}/coefs_splicing.pickle.gz \
                    --coefs_genexpr_file={input.coefs_dir}/coefs_genexpr.pickle.gz \
                    --coefs_intercept_file={input.coefs_dir}/coefs_intercept.pickle.gz \
                    --output_dir={output} \
                    --n_jobs={threads} \
                    --log_transform
        """
        
        
rule diff_tpm_encore:
    input:
        metadata = os.path.join(PREP_DIR,'metadata','ENCORE.tsv.gz'),
        genexpr = os.path.join(RAW_DIR,'ENCODE','ENCORE','vast_out','TPM-hg38-1097.tab.gz')
    output:
        diff_tpm = os.path.join(RESULTS_DIR,'files','ENCORE','diff_tpm.tsv.gz')
    run:
        import pandas as pd
        import numpy as np
        
        metadata = pd.read_table(input.metadata)
        genexpr = pd.read_table(input.genexpr, index_col=[0,1])
        
        genexpr = np.log2(genexpr + 1)
        genexpr.columns = [c.replace("_1","") for c in genexpr.columns]
        
        # as the difference between conditions and the mean of the conditions
        diff_tpm = {}
        for sample_oi in metadata["sampleID"]:
            # get the controls of the sample
            ctls = metadata.loc[metadata["sampleID"]==sample_oi, "control_samples"].values[0]
            
            # controls will be np.nan
            if isinstance(ctls,str):
                ctls = ctls.split(",")
                tpm_ctls = genexpr[ctls].mean(axis=1)
                
                # compute log2 fold-change
                dtpm = genexpr[sample_oi] - tpm_ctls
                
                diff_tpm[sample_oi] = dtpm
                
                del dtpm, tpm_ctls, ctls
                
        
        diff_tpm = pd.DataFrame(diff_tpm)
        
        # save
        diff_tpm.reset_index().to_csv(output.diff_tpm, sep="\t", index=False, compression="gzip")
        
        
rule delta_psi_encore:
    input:
        metadata = os.path.join(PREP_DIR,'metadata','ENCORE.tsv.gz'),
        psi = os.path.join(PREP_DIR,'event_psi','ENCORE-{event_type}.tsv.gz')
    output:
        delta_psi = os.path.join(RESULTS_DIR,'files','ENCORE','delta_psi-{event_type}.tsv.gz'),
        delta_psi_rel = os.path.join(RESULTS_DIR,'files','ENCORE','delta_psi_rel-{event_type}.tsv.gz')
    run:
        import pandas as pd
        import numpy as np
        
        metadata = pd.read_table(input.metadata)
        psi = pd.read_table(input.psi, index_col=0)
        
        # delta PSI as the difference between conditions and the mean of the conditions
        delta_psi = {}
        delta_psi_rel = {}
        for sample_oi in metadata["sampleID"]:
            # get the controls of the sample
            ctls = metadata.loc[metadata["sampleID"]==sample_oi, "control_samples"].values[0]
            
            # controls will be np.nan
            if isinstance(ctls,str):
                ctls = ctls.split(",")
                psi_ctls = psi[ctls].mean(axis=1)
                
                # compute delta PSI
                dpsi = psi[sample_oi] - psi_ctls
                
                # compute Glass' delta PSI
                pseudocount = psi[ctls].std(axis=1).mean()
                rel_dpsi = dpsi / (psi[ctls].std(axis=1) + pseudocount)
                
                delta_psi[sample_oi] = dpsi
                delta_psi_rel[sample_oi] = rel_dpsi
                
                del dpsi, rel_dpsi, psi_ctls, ctls
                
        
        delta_psi = pd.DataFrame(delta_psi)
        delta_psi_rel = pd.DataFrame(delta_psi_rel)
        
        # save
        delta_psi.reset_index().to_csv(output.delta_psi, sep="\t", index=False, compression="gzip")
        delta_psi_rel.reset_index().to_csv(output.delta_psi_rel, sep="\t", index=False, compression="gzip")
        

rule delta_spldep_encore:
    input:
        metadata = os.path.join(PREP_DIR,'metadata','ENCORE.tsv.gz'),
        spldep_dir = os.path.join(RESULTS_DIR,'files','ENCORE','splicing_dependency-{event_type}')
    output:
        delta_spldep = os.path.join(RESULTS_DIR,'files','ENCORE','delta_spldep-{event_type}.tsv.gz'),
    run:
        import os
        import pandas as pd
        import numpy as np
        
        metadata = pd.read_table(input.metadata)
        spldep = pd.read_table(os.path.join(input.spldep_dir,"mean.tsv.gz"), index_col=0)
        
        # delta Spl. Dep. as the difference between conditions and the mean of the conditions
        delta_spldep = {}
        for sample_oi in metadata["sampleID"]:
            # get the controls of the sample
            ctls = metadata.loc[metadata["sampleID"]==sample_oi, "control_samples"].values[0]
            
            # controls will be np.nan
            if isinstance(ctls,str):
                ctls = ctls.split(",")
                spldep_ctls = spldep[ctls].mean(axis=1)
                
                # compute delta PSI (Glass' delta)
                dspldep = (spldep[sample_oi] - spldep_ctls) / spldep[ctls].std(axis=1)
                
                delta_spldep[sample_oi] = dspldep
                
                del dspldep, spldep_ctls, ctls
                
        
        delta_spldep = pd.DataFrame(delta_spldep)
        
        # save
        delta_spldep.reset_index().to_csv(output.delta_spldep, sep="\t", index=False, compression="gzip")
        

rule make_ontology:
    input:
        metadata = os.path.join(PREP_DIR,'metadata','ENCORE.tsv.gz'),
        delta_psi = os.path.join(RESULTS_DIR,'files','ENCORE','delta_psi-{event_type}.tsv.gz')
    output:
        ontology = os.path.join(RESULTS_DIR,'files','ENCORE','kd_gene_sets-{event_type}.tsv.gz')
    params:
        thresh = 10
    run:
        import pandas as pd
        import numpy as np
        from tqdm import tqdm
        
        # load
        metadata = pd.read_table(input.metadata)
        delta_psi = pd.read_table(input.delta_psi)
        
        # make ontology
        metadata["kd_lab"] = metadata["KD"] + "_" + metadata["cell_line"]
        
        ontology = []
        for lab in tqdm(metadata["kd_lab"].unique()):
            samples_oi = list(metadata.loc[metadata["kd_lab"]==lab,"sampleID"])
            
            gene_set = delta_psi[["EVENT"]+samples_oi]\
                        .melt(id_vars=["EVENT"], var_name="sampleID")\
                        .dropna()\
                        .groupby(["EVENT"])["value"]\
                        .mean().reset_index()
            gene_set = gene_set.loc[np.abs(gene_set["value"])>params.thresh]
            gene_set = gene_set.drop(columns=["value"])
            gene_set["term"] = lab
            
            ontology.append(gene_set[["term","EVENT"]])
            
        ontology = pd.concat(ontology)
        
        ontology.to_csv(output.ontology, sep="\t", index=False, compression="gzip")
        
        
rule harm_score_encore:
    input:
        metadata = os.path.join(PREP_DIR,'metadata','ENCORE.tsv.gz'),
        spldep_dir = os.path.join(RESULTS_DIR,'files','ENCORE','splicing_dependency-{event_type}'),
        delta_spldep = os.path.join(RESULTS_DIR,'files','ENCORE','delta_spldep-{event_type}.tsv.gz'),
        delta_psi = os.path.join(RESULTS_DIR,'files','ENCORE','delta_psi-{event_type}.tsv.gz'),
        delta_psi_rel = os.path.join(RESULTS_DIR,'files','ENCORE','delta_psi_rel-{event_type}.tsv.gz')
    output:
        harm_score = os.path.join(RESULTS_DIR,'files','ENCORE','harm_score-{event_type}.tsv.gz'),
        harm_score_rel = os.path.join(RESULTS_DIR,'files','ENCORE','harm_score_rel-{event_type}.tsv.gz')
    run:
        import os
        import pandas as pd
        import numpy as np
        
        # load
        metadata = pd.read_table(input.metadata)
        spldep = pd.read_table(os.path.join(input.spldep_dir,"mean.tsv.gz"), index_col=0)
        delta_spldep = pd.read_table(input.delta_spldep, index_col=0)
        delta_psi = pd.read_table(input.delta_psi, index_col=0)
        delta_psi_rel = pd.read_table(input.delta_psi_rel, index_col=0)
        
        # compute ratio spldep/dpsi for the corresponding controls of each condition
        harm_score = {}
        harm_score_rel = {}
        for sample_oi in delta_psi.columns:
            # get deltas
            dspldep = delta_spldep[sample_oi]
            dpsi = delta_psi[sample_oi]
            dpsi_rel = delta_psi_rel[sample_oi]
            
            # get the controls of the sample
            ctls = metadata.loc[metadata["sampleID"]==sample_oi, "control_samples"].values[0]
            ctls = ctls.split(",")
            
            # get the average splicing dependency of the controls
            ctls_spldep = spldep[ctls].mean(axis=1)
            
            # normalize splicing dependency by delta psi
            harm_score[sample_oi] = dpsi * ctls_spldep
            harm_score_rel[sample_oi] = dpsi_rel * ctls_spldep
                        
        harm_score = pd.DataFrame(harm_score)
        harm_score_rel = pd.DataFrame(harm_score_rel)
        
        # save
        harm_score.reset_index()\
                   .to_csv(output.harm_score, sep="\t", index=False, compression="gzip")
        harm_score_rel.reset_index()\
                   .to_csv(output.harm_score_rel, sep="\t", index=False, compression="gzip")

        
rule compute_splicing_dependency_exon_crispr_screen_datsets:
    input:
        psi = os.path.join(RAW_DIR,'articles','{dataset}','vast_out','PSI-minN_1-minSD_0-noVLOW-min_ALT_use25-Tidy.tab.gz'),
        genexpr = lambda wildcards: os.path.join(RAW_DIR,'articles','{dataset}','vast_out','TPM-hg38-{n_samples}.tab.gz').format(dataset=wildcards.dataset, n_samples=N_SAMPLES[wildcards.dataset]),
        coefs_dir = os.path.join(RESULTS_DIR,'files','models_gene_dependency-{event_type}')
    output:
        directory(os.path.join(RESULTS_DIR,'files','{dataset}','splicing_dependency-{event_type}'))
    threads: 15
    resources:
        runtime = 86400, # seconds = 24h = 1 day
        memory = 30
    params:
        script_dir = TS_DIR
    shell:
        """
        nice python {params.script_dir}/target_spotter spldep_predict \
                    --splicing_file={input.psi} \
                    --genexpr_file={input.genexpr} \
                    --coefs_splicing_file={input.coefs_dir}/coefs_splicing.pickle.gz \
                    --coefs_genexpr_file={input.coefs_dir}/coefs_genexpr.pickle.gz \
                    --coefs_intercept_file={input.coefs_dir}/coefs_intercept.pickle.gz \
                    --output_dir={output} \
                    --n_jobs={threads} \
                    --log_transform
        """
        
        
rule model_gene_dependency_achilles:
    input:
        splicing_file = os.path.join(PREP_DIR,'event_psi','CCLE-{event_type}.tsv.gz'),
        genexpr_file = os.path.join(PREP_DIR,'genexpr_tpm','CCLE.tsv.gz'),
        gene_dependency_file = os.path.join(PREP_DIR,'achilles','CCLE_comparable.tsv.gz'),
        mapping_file = os.path.join(RAW_DIR,'VastDB','event_annotation-Hs2.tsv.gz')
    output:
        directory(os.path.join(RESULTS_DIR,'files','achilles','models_gene_dependency-{event_type}'))
    threads: 24
    resources:
        runtime = 604800, # seconds = 168h = 7 days
        memory = 30
    params:
        script_dir = TS_DIR,
        n_iterations = 1000
    shell:
        """
        nice python {params.script_dir}/target_spotter spldep_fit \
                    --gene_dependency_file={input.gene_dependency_file} \
                    --splicing_file={input.splicing_file} \
                    --genexpr_file={input.genexpr_file} \
                    --mapping_file={input.mapping_file} \
                    --output_dir={output} \
                    --n_iterations={params.n_iterations} \
                    --n_jobs={threads} \
                    --log_transform
        """
        
        
rule ppi_cosmic_closeness_real:
    input:
        ppi = os.path.join(PREP_DIR,'ppi','STRINGDB.tsv.gz'),
        seed_nodes = os.path.join(RESULTS_DIR,'files','selected_models-{event_type}-genes.txt'),
        sink_nodes = os.path.join(PREP_DIR,'gene_sets','cancer_gene_census.txt')
    output:
        os.path.join(RESULTS_DIR,'files','COSMIC','ppi_closeness-{event_type}','real.tsv.gz')
    threads: 12
    resources:
        runtime = 3600*6, # 6h
        memory = 6
    shell:
        """
        python scripts/ppi_compute_closeness.py \
                    --ppi_file={input.ppi} \
                    --seed_nodes_file={input.seed_nodes} \
                    --sink_nodes_file={input.sink_nodes} \
                    --output_file={output} \
                    --n_jobs={threads}
        """
        

rule ppi_cosmic_closeness_random:
    input:
        ppi = os.path.join(PREP_DIR,'ppi','STRINGDB.tsv.gz'),
        seed_nodes = os.path.join(RESULTS_DIR,'files','random_model_selection-{event_type}-{n_random_it}its','genes','{it}.txt').format(n_random_it=N_RANDOM_MODELS, event_type='{event_type}', it='{it}'),
        sink_nodes = os.path.join(PREP_DIR,'gene_sets','cancer_gene_census.txt')
    output:
        os.path.join(RESULTS_DIR,'files','COSMIC','ppi_closeness-{event_type}','random_it{it}.tsv.gz')
    threads: 1
    resources:
        runtime = 3600*8, # 6h
        memory = 6
    shell:
        """
        nice python scripts/ppi_compute_closeness.py \
                    --ppi_file={input.ppi} \
                    --seed_nodes_file={input.seed_nodes} \
                    --sink_nodes_file={input.sink_nodes} \
                    --output_file={output}
        """

        
rule combine_ppi_cosmic_closeness:
    input:
        closeness = [os.path.join(RESULTS_DIR,'files','COSMIC','ppi_closeness-{event_type}','real.tsv.gz')] + [os.path.join(RESULTS_DIR,'files','COSMIC','ppi_closeness-{event_type}','random_it{it}.tsv.gz').format(event_type="{event_type}", it=it) for it in list(range(N_RANDOM_MODELS))]
    output:
        closeness = os.path.join(RESULTS_DIR,'files','COSMIC','ppi_closeness-{event_type}','merged.tsv.gz')
    run:
        import os
        import pandas as pd
        
        dfs = []
        for f in input.closeness:
            dataset_id = os.path.basename(f).replace(".tsv.gz","")
            
            print(dataset_id)
            
            df = pd.read_table(f)
            df["dataset_id"] = dataset_id
            dfs.append(df)
            
        dfs = pd.concat(dfs)
        
        dfs.to_csv(output.closeness, sep="\t", compression="gzip", index=False)
        