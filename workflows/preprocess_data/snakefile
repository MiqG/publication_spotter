"""
Author: Miquel Anglada Girotto
Contact: miquelangladagirotto [at] gmail [dot] com

Workflow purpose
--------------
Preprocess raw data.

Outline
-------
- Spl. Dep. inference
    1. preprocess CCLE
        - metadata
        - PSI
        - gene expression
        - mutations: gene mutation frequency
    2. preprocess DepMap: demeter2 gene dependency
    
- Spl. Dep. validation
    1. preprocess Thomas2020
    2. preprocess ENCORE
    3. preprocess COSMIC
    4. preprocess TCGA
    5. preprocess inhouse

- Drug-Exon Inference
    1. preprocess STRINGDB
    2. preprocess GDSC

- Drug-Exon Validation
    1. preprocess Pietila2021

"""

import os
import pandas as pd

# variables
ROOT = os.path.dirname(os.path.dirname(os.getcwd()))
RAW_DIR = os.path.join(ROOT,"data","raw")
SRC_DIR = os.path.join(ROOT,"src")
PREP_DIR = os.path.join(ROOT,"data","prep")
SUPPORT_DIR = os.path.join(ROOT,"support")

EVENT_TYPES = ["EX"]
CANCER_TYPES = [
    "BLCA",
    "BRCA",
    "COAD",
    "HNSC",
    "KICH",
    "KIRC",
    "KIRP",
    "LIHC",
    "LUAD",
    "LUSC",
    "PRAD",
    "THCA",
    "UCEC"
]

SAVE_PARAMS = {"sep":"\t", "index":False, "compression":"gzip"}

DEPMAP_RAW = {
    "demeter2": os.path.join(RAW_DIR,"DepMap","demeter2","D2_combined_gene_dep_scores.csv"),
    "achilles": os.path.join(RAW_DIR,"DepMap","achilles_ccle","Achilles_gene_effect_transposed.tsv.gz")
}

tcga_metadata = pd.read_table(os.path.join(RAW_DIR,"TCGA","metadata","PANCAN.tsv.gz"))
TCGA_N_SAMPLES = tcga_metadata["cancer_type"].value_counts().to_dict()

TRANSCRIPTS_DATASETS = ["gencode.v44.transcripts"] # ,"gencode.v26.transcripts","human.all.rna"]

##### RULES #####
rule all:
    input:
        os.path.join(PREP_DIR,"demeter2","shRNA-mapping_to_vastdb_exons.tsv.gz"),
        expand(os.path.join(PREP_DIR,"bowtie_indices","{transcripts_dataset}"), transcripts_dataset=TRANSCRIPTS_DATASETS),
        os.path.join(RAW_DIR,"DepMap","demeter2","shRNA-mapping.fasta"),
        expand(os.path.join(PREP_DIR,"demeter2","shRNA_to_{transcripts_dataset}.bam"), transcripts_dataset=TRANSCRIPTS_DATASETS),
        expand(os.path.join(PREP_DIR,"demeter2","shRNA_to_{transcripts_dataset}.bed"), transcripts_dataset=TRANSCRIPTS_DATASETS),
        expand(os.path.join(PREP_DIR,"demeter2","shRNA_to_{transcripts_dataset}-mapping_coords.tsv.gz"), transcripts_dataset=TRANSCRIPTS_DATASETS)
#         # preprocess CCLE
#         ## metadata
#         os.path.join(PREP_DIR,"metadata","CCLE.tsv.gz"),
#         ## PSI
#         expand(os.path.join(PREP_DIR,"event_psi","CCLE-{event_type}.tsv.gz"), event_type=EVENT_TYPES),
#         ## gene expression
#         os.path.join(PREP_DIR,"genexpr_tpm","CCLE.tsv.gz"),

#         # preprocess DepMap data
#         expand(os.path.join(PREP_DIR,"{dataset}","CCLE.tsv.gz"), dataset=DEPMAP_RAW.keys()),
#         # map shRNAs to exons
#         os.path.join(PREP_DIR,"demeter2","shRNA-mapping_coords.tsv.gz"),
#         # make Achilles comparable to Demeter2
#         os.path.join(PREP_DIR,"achilles","CCLE_comparable.tsv.gz"),
        
#         # preprocess Thomas 2020
#         os.path.join(PREP_DIR,"Thomas2020","crispr_screen.tsv.gz"),

#         # preprocess ENCORE
#         os.path.join(PREP_DIR,"metadata","ENCORE.tsv.gz"),
#         os.path.join(PREP_DIR,"event_psi","ENCORE-EX.tsv.gz"),
#         os.path.join(PREP_DIR,"event_psi","ENCORE-ALTA.tsv.gz"),
#         os.path.join(PREP_DIR,"event_psi","ENCORE-ALTD.tsv.gz"),
#         os.path.join(PREP_DIR,"event_psi","ENCORE-INT.tsv.gz"),
#         os.path.join(PREP_DIR,"genexpr_tpm","ENCORE.tsv.gz"),
        
#         # make COSMIC gene set
#         os.path.join(PREP_DIR,"gene_sets","cancer_gene_census.txt"),
                
#         # preprocess TCGA
#         expand(os.path.join(PREP_DIR,"metadata","{cancer}.tsv.gz"), cancer=CANCER_TYPES),
#         expand(os.path.join(PREP_DIR,"event_psi","{cancer}-EX.tsv.gz"), cancer=CANCER_TYPES),
#         expand(os.path.join(PREP_DIR,"event_psi","{cancer}-ALTA.tsv.gz"), cancer=CANCER_TYPES),
#         expand(os.path.join(PREP_DIR,"event_psi","{cancer}-ALTD.tsv.gz"), cancer=CANCER_TYPES),
#         expand(os.path.join(PREP_DIR,"event_psi","{cancer}-INT.tsv.gz"), cancer=CANCER_TYPES),
#         expand(os.path.join(PREP_DIR,"genexpr_counts","{cancer}.tsv.gz"), cancer=CANCER_TYPES),
#         ## merge metadata TCGA
#         os.path.join(PREP_DIR,"metadata","PANCAN.tsv.gz"),
#         ## clinically relevant subtypes
#         expand(os.path.join(PREP_DIR,"metadata","{cancer}_subtypes.tsv.gz"), cancer=CANCER_TYPES),
#         ## merge metadata TCGA subtypes
#         os.path.join(PREP_DIR,"metadata","PANCAN_subtypes.tsv.gz"),
        
#         # preprocess inhouse RNA-seq
#         os.path.join(PREP_DIR,"metadata","inhouse.tsv.gz"),
#         os.path.join(PREP_DIR,"event_psi","inhouse-EX.tsv.gz"),
#         os.path.join(PREP_DIR,"event_psi","inhouse-ALTA.tsv.gz"),
#         os.path.join(PREP_DIR,"event_psi","inhouse-ALTD.tsv.gz"),
#         os.path.join(PREP_DIR,"event_psi","inhouse-INT.tsv.gz"),
#         os.path.join(PREP_DIR,"genexpr_tpm","inhouse.tsv.gz"),        

#         # preprocess STRINGDB
#         os.path.join(PREP_DIR,"ppi","STRINGDB.tsv.gz"),

#         # preprocess drug screens GDSC
#         ## split datasets GDSC platforms
#         os.path.join(PREP_DIR,"drug_screens","train","GDSC1.tsv.gz"),
#         os.path.join(PREP_DIR,"drug_screens","train","GDSC2.tsv.gz"),
#         os.path.join(PREP_DIR,"drug_screens","test","GDSC1.tsv.gz"),
#         os.path.join(PREP_DIR,"drug_screens","test","GDSC2.tsv.gz"),
#         ## clean names
#         os.path.join(PREP_DIR,"drug_screens","drug_targets.tsv.gz"),
        
#         # preprocess Pietila2021
#         os.path.join(PREP_DIR,"metadata","Pietila2021.tsv.gz"),
#         os.path.join(PREP_DIR,"event_psi","Pietila2021-EX.tsv.gz"),
#         os.path.join(PREP_DIR,"event_psi","Pietila2021-ALTA.tsv.gz"),
#         os.path.join(PREP_DIR,"event_psi","Pietila2021-ALTD.tsv.gz"),
#         os.path.join(PREP_DIR,"event_psi","Pietila2021-INT.tsv.gz"),
#         os.path.join(PREP_DIR,"genexpr_tpm","Pietila2021.tsv.gz"),
        
        
rule prepare_metadata_ccle:
    input:
        sample_info = os.path.join(RAW_DIR,"DepMap","achilles_ccle","sample_info.csv"),
        ccle_cancertypes = os.path.join(RAW_DIR,"articles","Yu2019","ccle_metadata.xls"),
        sample_annotation = os.path.join(RAW_DIR,"CCLE","ENA_filereport-PRJNA523380-CCLE.tsv")
    output:
        os.path.join(PREP_DIR,"metadata","CCLE.tsv.gz")
    params:
        dataset = "metadata"
    shell:
        """
        python scripts/preprocess_ccle.py \
                    --dataset={params.dataset} \
                    --sample_info_file={input.sample_info} \
                    --ccle_cancer_types_file={input.ccle_cancertypes} \
                    --sample_annot_file={input.sample_annotation} \
                    --output_file={output}
        """


rule preprocess_psi_ccle:
    input:
        psi_file = os.path.join(RAW_DIR,'CCLE','vast_out','PSI-minN_1-minSD_0-noVLOW-min_ALT_use25-Tidy.tab.gz'),
        metadata_file = os.path.join(PREP_DIR,'metadata','CCLE.tsv.gz')
    output:
        os.path.join(PREP_DIR,'event_psi','CCLE-{event_type}.tsv.gz')
    params:
        dataset = 'event_psi',
        event_type = '{event_type}',
    shell:
        """
        python scripts/preprocess_ccle.py \
                    --dataset={params.dataset} \
                    --event_type={params.event_type} \
                    --mat_file={input.psi_file} \
                    --metadata_file={input.metadata_file} \
                    --output_file={output} \
        """
        
        
rule preprocess_genexpr_ccle:
    input:
        genexpr = os.path.join(RAW_DIR,'CCLE','vast_out','TPM-hg38-1019.tab.gz'),
        metadata = os.path.join(PREP_DIR,'metadata','CCLE.tsv.gz')
    output:
        genexpr = os.path.join(PREP_DIR,'genexpr_tpm','CCLE.tsv.gz')
    params:
        dataset = 'genexpr_vast'
    shell:
        """
        python scripts/preprocess_ccle.py \
                    --dataset={params.dataset} \
                    --mat_file={input.genexpr} \
                    --metadata_file={input.metadata} \
                    --output_file={output.genexpr}
        """


rule shrnas_mapping_exons:
    input:
        shrnas = os.path.join(RAW_DIR,"DepMap","demeter2","shRNA-mapping.csv"),
        exon_info = os.path.join(RAW_DIR,"VastDB","EVENT_INFO-hg38.tab.gz")
    output:
        mapping = os.path.join(PREP_DIR,"demeter2","shRNA-mapping_to_vastdb_exons.tsv.gz")
    run:
        import pandas as pd
        from tqdm import tqdm
        import numpy as np
        
        # load
        shrnas = pd.read_csv(input.shrnas)
        exon_info = pd.read_table(input.exon_info)
        
        # subset
        ## only exons
        exon_info = exon_info.loc[exon_info["EVENT"].str.contains("EX")].copy()
        
        ## same shRNA targets
        common_genes = set(shrnas["Gene Symbol"]).intersection(exon_info["GENE"])
        shrnas = shrnas.loc[shrnas["Gene Symbol"].isin(common_genes)].copy()
        exon_info = exon_info.loc[exon_info["GENE"].isin(common_genes)].copy()
        # 7 because it is the shRNA seed sequence length
        exon_info["full_sequence"] = exon_info["Seq_C1"].str[-7:]+exon_info["Seq_A"]+exon_info["Seq_C2"].str[:7]
        
        # find to which exon(s) within the gene each shRNA maps
        mapping = []
        for gene_oi in tqdm(list(common_genes)):
            gene_shrnas = shrnas.loc[shrnas["Gene Symbol"] == gene_oi]
            gene_exon_info = exon_info.loc[exon_info["GENE"] == gene_oi]
            
            mapping_shrnas = []
            for shrna_oi in gene_shrnas["Barcode Sequence"]:
                # consider only first 19 nucleotides of shRNAs (like in McFarland 2018)
                idx = gene_exon_info["full_sequence"].str.contains(shrna_oi[:19])
                events = gene_exon_info.loc[idx,"EVENT"].tolist()
                mapping_shrna = pd.DataFrame({
                    "shrna_barcode": shrna_oi, 
                    "GENE": gene_oi,
                    "EVENT": events if len(events)>0 else [np.nan]
                })
                mapping_shrnas.append(mapping_shrna)
                
            mapping.append(pd.concat(mapping_shrnas))
            
        mapping = pd.concat(mapping)        
        
        # save
        mapping.to_csv(output.mapping, **SAVE_PARAMS)
        
        print("Done!")


rule build_index_bowtie_human_transcriptome:
    input:
        reference = os.path.join(RAW_DIR,"GENCODE","{transcripts_dataset}.fa.gz")
    output:
        index_dir = directory(os.path.join(PREP_DIR,"bowtie_indices","{transcripts_dataset}"))
    threads: 24
    shell:
        """
        set -eo pipefail
        
        mkdir {output.index_dir}
        bowtie-build --threads {threads} \
                    {input.reference} \
                    {output.index_dir}/index

        echo "Done!"
        """


rule shRNAs_to_fasta:
    input:
        shrnas = os.path.join(RAW_DIR,"DepMap","demeter2","shRNA-mapping.csv")
    output:
        shrnas = os.path.join(RAW_DIR,"DepMap","demeter2","shRNA-mapping.fasta")
    run:
        import pandas as pd

        # load
        shrnas = pd.read_csv(input.shrnas)

        # prep (keep 19-mer)
        shrnas["fasta_id"] = shrnas["Barcode Sequence"] + "|" + shrnas["Gene Symbol"]
        shrnas["fasta_sequence"] = shrnas["Barcode Sequence"].str[:19]

        # save fasta
        def write_fasta(df, filename):
            with open(filename, 'w') as file:
                for index, row in df.iterrows():
                    file.write(f'>{row["fasta_id"]}\n{row["fasta_sequence"]}\n')
        
        write_fasta(shrnas, output.shrnas)

        print("Done!")


rule align_shRNAs_to_human_transcriptome:
    input:
        shRNA_fasta = os.path.join(RAW_DIR,"DepMap","demeter2","shRNA-mapping.fasta"),
        index_dir = os.path.join(PREP_DIR,"bowtie_indices","{transcripts_dataset}")
    output:
        alignment = os.path.join(PREP_DIR,"demeter2","shRNA_to_{transcripts_dataset}.bam")
    params:
        alignment_sam = os.path.join(PREP_DIR,"demeter2","shRNA_to_{transcripts_dataset}.sam")
    threads: 24
    shell:
        """
        set -eo pipefail

        # align
        bowtie --threads {threads} \
               -v 0 \
               -x {input.index_dir}/index \
               -f {input.shRNA_fasta} \
               -S {params.alignment_sam}
        
        # convert sam to bam
        samtools view --threads {threads} -b -o {output.alignment} {params.alignment_sam}
        
        rm {params.alignment_sam}
        
        echo "Done!"
        """

rule convert_alignment_to_bed:
    input:
        sam = os.path.join(PREP_DIR,"demeter2","shRNA_to_{transcripts_dataset}.bam")
    output:
        bed = os.path.join(PREP_DIR,"demeter2","shRNA_to_{transcripts_dataset}.bed")
    shell:
        """
        set -eo pipefail

        bedtools bamtobed -i {input.sam} > {output.bed}
        
        echo "Done!"
        """

# rule get_shrna_genomic_coordinates:
#     input:
#         alignment = os.path.join(PREP_DIR,"demeter2","shRNA_to_gencode.v44.transcripts.bed")
#     output:
#         mapping = os.path.join(PREP_DIR,"demeter2","shRNA-mapping_coords.tsv.gz")
#     run:
#         import pandas as pd
#         import pyensembl

#         # load
#         alignment = pd.read_table(
#             input.alignment, 
#             names=["transcript_id","start","end","shrna_id","rgb","strand"]
#         )
#         ensembl = pyensembl.EnsemblRelease(release=110)

#         # prep
#         alignment[
#             ["transcript_id","gene_id","havana_transcript","havana_gene",
#              "transcript_name","gene_name","entrez_id","gene_type","empty"]
#         ] = alignment["transcript_id"].str.split("|", expand=True)
#         alignment[["barcode_sequence","gene_name"]] = alignment["shrna_id"].str.split("|", expand=True)
#         alignment["tx_id"] = alignment["transcript_id"].str.split(".").str[0]

#         # get genomic coordinates from transcript coordinates
#         transcript_id = "ENST00000530003"

#         transcript = ensembl.transcript_by_id(transcript_id)
        
        
#         print("Done!")


rule get_shrna_genomic_coordinates:
    input:
        alignment = os.path.join(PREP_DIR,"demeter2","shRNA_to_{transcripts_dataset}.bed"),
        genome_annot = os.path.join(RAW_DIR,"GENCODE","Homo_sapiens.GRCh38.gencode_v44.sqlite")
    output:
        os.path.join(PREP_DIR,"demeter2","shRNA_to_{transcripts_dataset}-mapping_coords.tsv.gz")
    params:
        chunk_size = 500
    threads: 24
    shell:
        """
        Rscript scripts/get_shrna_genomic_coordinates.R \
                    --alignment_file={input.alignment} \
                    --genome_annot_file={input.genome_annot} \
                    --n_jobs={threads} \
                    --chunk_size={params.chunk_size} \
                    --output_file={output}
        """


rule preprocess_depmap:
    input:
        depmap = lambda wildcards: DEPMAP_RAW[wildcards.dataset],
        metadata = os.path.join(RAW_DIR,'DepMap','achilles_ccle','sample_info.csv')
    output:
        os.path.join(PREP_DIR,'{dataset}','CCLE.tsv.gz')
    shell:
        """
        python scripts/preprocess_depmap.py \
                    --raw_depmap_file={input.depmap} \
                    --raw_metadata_file={input.metadata} \
                    --prep_depmap_file={output}
        """
        
        
rule make_achilles_comparable_to_demeter2:
    input:
        demeter2 = os.path.join(PREP_DIR,"demeter2","CCLE.tsv.gz"),
        achilles = os.path.join(PREP_DIR,"achilles","CCLE.tsv.gz")
    output:
        achilles = os.path.join(PREP_DIR,"achilles","CCLE_comparable.tsv.gz")
    run:
        import numpy as np
        import pandas as pd
        
        demeter2 = pd.read_table(input.demeter2, index_col=0)
        achilles = pd.read_table(input.achilles, index_col=0)
        
        # subset samples and genes
        common_samples = set(demeter2.columns).intersection(achilles.columns)
        common_genes = set(demeter2.index).intersection(achilles.index)
        demeter2 = demeter2.loc[common_genes,common_samples].copy()
        achilles = achilles.loc[common_genes,common_samples].copy()
        
        # replicate missing values
        is_missing = demeter2.isnull().values
        achilles.values[is_missing] = np.nan
        
        # save 
        achilles.reset_index().to_csv(output.achilles, sep="\t", index=False, compression="gzip")
        
        print("Done!")
        
        
rule mutation_frequency:
    input:
        snv = os.path.join(RAW_DIR,'DepMap','achilles_ccle','CCLE_mutations.csv'),
        annotation = os.path.join(RAW_DIR,'ENSEMBL','gene_annotation-hg19.tsv.gz')
    output:
        os.path.join(PREP_DIR,'gene_mutation_freq','CCLE.tsv.gz')
    params:
        id_col = 'DepMap_ID',
        gene_col = 'Hugo_Symbol',
        effect_col = 'Variant_Classification'
    shell:
        """
        python scripts/count_mutations_per_gene_and_variant.py \
                    --snv_file={input.snv} \
                    --annotation_file={input.annotation} \
                    --id_col={params.id_col} \
                    --gene_col={params.gene_col} \
                    --effect_col={params.effect_col} \
                    --output_file={output}
        """
        
rule make_cosmic_gene_set:
    input:
        cosmic = os.path.join(RAW_DIR,"COSMIC","cancer_gene_census.tsv")
    output:
        cosmic = os.path.join(PREP_DIR,"gene_sets","cancer_gene_census.txt")
    run:
        import pandas as pd
        
        df = pd.read_table(input.cosmic)
        gene_set = df["Gene Symbol"]
        gene_set.to_csv(output.cosmic, sep="\t", index=False, header=None)
        
        
rule prepare_thomas2020:
    input:
        screen = os.path.join(RAW_DIR,'articles','Thomas2020','crispr_screen.xlsx'),
        mapping = os.path.join(RAW_DIR,'articles','Thomas2020','event_mapping_vastdb.tsv')
    output:
        os.path.join(PREP_DIR,'Thomas2020','crispr_screen.tsv.gz')
    shell:
        """
        Rscript scripts/preprocess_Thomas2020.R \
                    --thomas_crispr_screen_file={input.screen} \
                    --thomas_event_mapping_file={input.mapping} \
                    --output_file={output}
        """


rule preprocess_encore:
    input:
        metadata = os.path.join(RAW_DIR,'ENCODE','ENCORE','metadata','ENCORE.tsv'),
        psi = os.path.join(RAW_DIR,'ENCODE','ENCORE','vast_out','PSI-minN_1-minSD_0-noVLOW-min_ALT_use25-Tidy.tab.gz'),
        genexpr = os.path.join(RAW_DIR,'ENCODE','ENCORE','vast_out','TPM-hg38-1097.tab.gz')
    output:
        metadata = os.path.join(PREP_DIR,'metadata','ENCORE.tsv.gz'),
        psi_EX = os.path.join(PREP_DIR,'event_psi','ENCORE-EX.tsv.gz'),
        psi_ALTA = os.path.join(PREP_DIR,'event_psi','ENCORE-ALTA.tsv.gz'),
        psi_ALTD = os.path.join(PREP_DIR,'event_psi','ENCORE-ALTD.tsv.gz'),
        psi_INT = os.path.join(PREP_DIR,'event_psi','ENCORE-INT.tsv.gz'),
        genexpr = os.path.join(PREP_DIR,'genexpr_tpm','ENCORE.tsv.gz')
    run:
        import gc
        import pandas as pd
        import numpy as np
        
        # load
        print("Loading data...")
        metadata = pd.read_table(input.metadata)
        psi = pd.read_table(input.psi, index_col=0)
        genexpr = pd.read_table(input.genexpr, index_col=[0,1])
        
        gc.collect()
        
        # metadata
        print("Processing metadata...")
        ## sample names
        metadata["sampleID"] = metadata["dbxrefs"].str.replace("SRA:","")
        ## cell lines info
        metadata["cell_line"] = metadata["Biosample term name"]
        depmapids = {"K562":"ACH-000551", "HepG2":"ACH-000739"}
        metadata["DepMap_ID"] = [depmapids[c] for c in metadata["cell_line"]]
        ## KD info
        metadata["KD"] = metadata["Experiment target"].str.replace("-human","")
        ## experiment
        metadata["experiment"] = metadata["Experiment accession"]
        ## replicate
        metadata["replicate"] = metadata["Biological replicate(s)"]
        
        ## controls
        ctls_exps = []
        ctls_samps = []
        for idx, row in metadata.iterrows():
            if isinstance(row["Controlled by"], str):
                # get file accession controls
                accs = row["Controlled by"]\
                        .replace("files","")\
                        .replace("/","")\
                        .replace(" ","")\
                        .split(",")
                idx = metadata["File accession"].isin(accs)

                # get experiment accession
                exps = metadata.loc[idx, "experiment"].unique()
                
                # get sample accession
                samps = metadata.loc[idx, "sampleID"].unique()
                
                # save
                exps = ','.join(np.sort(exps))
                samps = ','.join(np.sort(samps))
                ctls_exps.append(exps)
                ctls_samps.append(samps)
            else:
                ctls_exps.append(np.nan)
                ctls_samps.append(np.nan)
        metadata["control_experiment"] = ctls_exps
        metadata["control_samples"] = ctls_samps
        
        cols_oi = ['sampleID','cell_line', 'DepMap_ID', 'KD', 'experiment', 
                   'control_experiment', 'control_samples','replicate']
        metadata = metadata[cols_oi].drop_duplicates()
        
        # PSI
        print("Processing PSI matrix...")
        ## drop empty rows
        is_na = psi.isnull()
        non_missing = is_na.shape[1] - is_na.sum(1)
        to_keep = non_missing >= 1
        psi = psi.loc[to_keep]
        
        ## remove vast-tools' suffix
        psi.columns = [c.replace('_1','') for c in psi.columns]
        
        ## split by event type
        event_types = ["EX","ALTA","ALTD","INT"]
        psis = {e: psi.loc[psi.index.str.contains(e)] for e in event_types}
        
        # TPM
        print("Processing TPM matrix...")
        ## remove vast-tools' suffix
        genexpr.columns = [c.replace('_1','') for c in genexpr.columns]
        
        # save
        print("Saving...")
        ## metadata
        metadata.to_csv(output.metadata, **SAVE_PARAMS)
        
        ## PSIs
        psis["EX"].reset_index().to_csv(output.psi_EX, **SAVE_PARAMS)
        psis["ALTD"].reset_index().to_csv(output.psi_ALTD, **SAVE_PARAMS)
        psis["ALTA"].reset_index().to_csv(output.psi_ALTA, **SAVE_PARAMS)
        psis["INT"].reset_index().to_csv(output.psi_INT, **SAVE_PARAMS)
        
        ## TPMs
        genexpr.reset_index().drop(columns='NAME').to_csv(output.genexpr, **SAVE_PARAMS)
        
        print("Done!")
        
        
rule preprocess_TCGA:
    input:
        metadata = os.path.join(RAW_DIR,"TCGA","metadata","{cancer}.tsv.gz"),
        psi = os.path.join(RAW_DIR,"TCGA","{cancer}","vast_out",'PSI-minN_1-minSD_0-noVLOW-min_ALT_use25-Tidy.tab.gz'),
    output:
        metadata = os.path.join(PREP_DIR,"metadata","{cancer}.tsv.gz"),
        psi_EX = os.path.join(PREP_DIR,"event_psi","{cancer}-EX.tsv.gz"),
        psi_ALTA = os.path.join(PREP_DIR,"event_psi","{cancer}-ALTA.tsv.gz"),
        psi_ALTD = os.path.join(PREP_DIR,"event_psi","{cancer}-ALTD.tsv.gz"),
        psi_INT = os.path.join(PREP_DIR,"event_psi","{cancer}-INT.tsv.gz")
    run:
        import gc
        import pandas as pd
        import numpy as np

        # load
        print("Loading data...")
        metadata = pd.read_table(input.metadata)
        psi = pd.read_table(input.psi, index_col=0)
        genexpr = pd.read_table(input.genexpr, index_col=[0,1])

        gc.collect()

        # preprocess metadata
        ## drop FFPE samples
        metadata = metadata.loc[~metadata["is_ffpe"],:].copy()

        # PSI
        print("Processing PSI matrix...")
        ## drop empty rows
        is_na = psi.isnull()
        non_missing = is_na.shape[1] - is_na.sum(1)
        to_keep = non_missing >= 1
        psi = psi.loc[to_keep]

        ## remove vast-tools' suffix
        psi.columns = [c.replace("_1","") for c in psi.columns]

        ## split by event type
        event_types = ["EX","ALTA","ALTD","INT"]
        psis = {e: psi.loc[psi.index.str.contains(e)] for e in event_types}        
        
        ## keep only the replicate with less missing values for each patient
        duplicated_sampleIDs = metadata.loc[metadata.duplicated('sampleID'),'sampleID'].unique()
        if len(duplicated_sampleIDs)>0:
            duplicated_file_ids = metadata.set_index('sampleID').loc[duplicated_sampleIDs,'file_id']

            # decide which sample to keep based on their missing values
            nan_count = psi[duplicated_file_ids].isnull().sum()
            file_ids_todrop = {sampleID: list(nan_count[duplicated_file_ids[sampleID]].sort_values().index[1:])
                               for sampleID in duplicated_file_ids.index.unique()}
            # drop samples
            file_ids_todrop = sum(list(file_ids_todrop.values()),[]) # unlist
            metadata = metadata.loc[~metadata['file_id'].isin(file_ids_todrop)]
            
        # subset
        ## find common samples
        common_samples = set(metadata["file_id"]).intersection(
            psis["EX"].columns
        ).intersection(
            genexpr.columns
        )
        psis = {e: psis[e][common_samples].copy() for e in event_types}
        genexpr = genexpr[common_samples].copy()
        metadata = metadata.loc[metadata["file_id"].isin(common_samples)]
        
        ## rename columns
        psis = {
            e: psis[e].rename(
                columns=metadata.set_index("file_id")["sampleID"].to_dict()
                ).copy() 
            for e in event_types
        }
        genexpr = genexpr.rename(
            columns=metadata.set_index("file_id")["sampleID"].to_dict()
        ).copy()        
            
        # save
        print("Saving...")
        ## metadata
        metadata.to_csv(output.metadata, **SAVE_PARAMS)
        ## PSIs
        psis["EX"].reset_index().to_csv(output.psi_EX, **SAVE_PARAMS)
        psis["ALTD"].reset_index().to_csv(output.psi_ALTD, **SAVE_PARAMS)
        psis["ALTA"].reset_index().to_csv(output.psi_ALTA, **SAVE_PARAMS)
        psis["INT"].reset_index().to_csv(output.psi_INT, **SAVE_PARAMS)

        print("Done!")
        
        
rule preprocess_tcga_genexpr_counts:
    input:
        genexpr = os.path.join(RAW_DIR,"GDC","gene_counts","{cancer}.tsv.gz")
    output:
        genexpr = os.path.join(PREP_DIR,"genexpr_counts","{cancer}.tsv.gz")
    run:
        import pandas as pd
        
        # load
        genexpr = pd.read_table(input.genexpr, index_col=0)
        
        # simplify column names
        genexpr.columns = [c[:15] for c in genexpr.columns]
        
        # simplify row names
        genexpr = genexpr.loc[~genexpr.index.str.contains("PAR_Y")]
        genexpr.index = [r.split(".")[0] for r in genexpr.index]
        
        # save
        genexpr.reset_index().to_csv(output.genexpr, **SAVE_PARAMS)
        
        print("Done!")
        
        
rule prep_cancer_subtypes:
    input:
        metadata = os.path.join(PREP_DIR,'metadata','{cancer}.tsv.gz'),
        subtypes = os.path.join(RAW_DIR,'articles','Mina2017','tcga_subtypes.xls')
    output:
        subtypes = os.path.join(PREP_DIR,'metadata','{cancer}_subtypes.tsv.gz')
    run:
        import pandas as pd
        
        subtypes = pd.read_excel(input.subtypes, skiprows=2)
        subtypes["sampleID"] = subtypes["Sample id"].str.replace(".","-",regex=False)
        subtypes["cancer_subtype"] = subtypes["Subtype"]
        subtypes = subtypes[["sampleID","cancer_subtype"]]
        
        metadata = pd.read_table(input.metadata)
        metadata = metadata[["file_id","sampleID","cancer_type","sample_type"]]
        
        df = pd.merge(metadata, subtypes, how="left", on="sampleID")
        
        # consider STN as a subtype
        df.loc[df["sample_type"]=="Solid Tissue Normal","cancer_subtype"] = "STN"
        
        df.to_csv(output.subtypes, sep="\t", index=False, compression="gzip")
        
        print("Done!")
        
        
rule merge_tcga_metadata:
    input:
        metadata_files = [os.path.join(PREP_DIR,'metadata','%s.tsv' % cancer) 
                          for cancer in CANCER_TYPES]
    output:
        os.path.join(PREP_DIR,'metadata','PANCAN.tsv.gz')
    run:
        import pandas as pd
        metadata = []
        for f in input.metadata_files:
            df = pd.read_table(f)
            metadata.append(df)
            del df
        metadata = pd.concat(metadata)
        metadata.to_csv(output[0], sep='\t', index=False, compression='gzip')
        
        print("Done!")
        
        
rule merge_tcga_metadata_subtypes:
    input:
        metadata_files = [os.path.join(PREP_DIR,'metadata','{cancer}_subtypes.tsv.gz').format(cancer=c) 
                          for c in CANCER_TYPES]
    output:
        os.path.join(PREP_DIR,'metadata','PANCAN_subtypes.tsv.gz')
    run:
        import pandas as pd
        metadata = []
        for f in input.metadata_files:
            df = pd.read_table(f)
            metadata.append(df)
            del df
        metadata = pd.concat(metadata)
        metadata.to_csv(output[0], sep='\t', index=False, compression='gzip')
        
        print("Done!")
        
        
rule preprocess_inhouse:
    input:
        psi = os.path.join(RAW_DIR,'inhouse','20230124-rnaseq_cancer_cell_lines','vast_out','PSI-minN_1-minSD_0-noVLOW-min_ALT_use25-Tidy.tab.gz'),
        genexpr = os.path.join(RAW_DIR,'inhouse','20230124-rnaseq_cancer_cell_lines','vast_out','TPM-hg38-3.tab.gz')
    output:
        metadata = os.path.join(PREP_DIR,'metadata','inhouse.tsv.gz'),
        psi_EX = os.path.join(PREP_DIR,'event_psi','inhouse-EX.tsv.gz'),
        psi_ALTA = os.path.join(PREP_DIR,'event_psi','inhouse-ALTA.tsv.gz'),
        psi_ALTD = os.path.join(PREP_DIR,'event_psi','inhouse-ALTD.tsv.gz'),
        psi_INT = os.path.join(PREP_DIR,'event_psi','inhouse-INT.tsv.gz'),
        genexpr = os.path.join(PREP_DIR,'genexpr_tpm','inhouse.tsv.gz')
    run:
        import gc
        import pandas as pd
        import numpy as np
        
        # load
        print("Loading data...")
        psi = pd.read_table(input.psi, index_col=0)
        genexpr = pd.read_table(input.genexpr, index_col=[0,1])
        
        gc.collect()
        
        # preprocess metadata
        metadata = pd.DataFrame({
            "CCLE_Name": [
                "A549_LUNG",
                "HT29_LARGE_INTESTINE",
                "MDAMB231_BREAST"
            ],
            "sampleID": [
                "a549_18496AAD_ATTATGTCAT-AATGCGGAAG_R1_001",
                "ht29_18495AAD_GACTCAAGTC-TGAAGAAGGC_R1_001",
                "mda_18556AAD_CTGGACTAAC-CTGATCACGG_R1_001"
            ],
            "DepMap_ID": ["ACH-000681","ACH-000552","ACH-000768"]
        })
        
        # PSI
        print("Processing PSI matrix...")
        ## drop empty rows
        is_na = psi.isnull()
        non_missing = is_na.shape[1] - is_na.sum(1)
        to_keep = non_missing >= 1
        psi = psi.loc[to_keep]
        
        ## rename vast-tools' suffix
        psi = psi.rename(columns=metadata.set_index("sampleID")["DepMap_ID"].to_dict())
        
        ## split by event type
        event_types = ["EX","ALTA","ALTD","INT"]
        psis = {e: psi.loc[psi.index.str.contains(e)] for e in event_types}        
        
        # TPM
        print("Processing TPM matrix...")
        ## remove vast-tools' suffix
        genexpr = genexpr.rename(columns=metadata.set_index("sampleID")["DepMap_ID"].to_dict())
        
        # save
        print("Saving...")
        
        ## metadata
        metadata.to_csv(output.metadata, **SAVE_PARAMS)
        
        ## PSIs
        psis["EX"].reset_index().to_csv(output.psi_EX, **SAVE_PARAMS)
        psis["ALTD"].reset_index().to_csv(output.psi_ALTD, **SAVE_PARAMS)
        psis["ALTA"].reset_index().to_csv(output.psi_ALTA, **SAVE_PARAMS)
        psis["INT"].reset_index().to_csv(output.psi_INT, **SAVE_PARAMS)
        
        ## TPMs
        genexpr.reset_index().drop(columns='NAME').to_csv(output.genexpr, **SAVE_PARAMS)        
        
        print("Done!")   
        
        
rule preprocess_gdsc:
    input:
        drug_screen = os.path.join(RAW_DIR,'DepMap','gdsc','sanger-dose-response.csv'),
        demeter2 = os.path.join(PREP_DIR,'demeter2','CCLE.tsv.gz')
    output:
        gdsc1_train = os.path.join(PREP_DIR,'drug_screens','train','GDSC1.tsv.gz'),
        gdsc1_test = os.path.join(PREP_DIR,'drug_screens','test','GDSC1.tsv.gz'),
        gdsc2_train = os.path.join(PREP_DIR,'drug_screens','train','GDSC2.tsv.gz'),
        gdsc2_test = os.path.join(PREP_DIR,'drug_screens','test','GDSC2.tsv.gz'),
    run:
        import pandas as pd
        SAVE_KWS = {"sep":"\t", "index":False, "compression":"gzip"}
        drug_response = pd.read_csv(input.drug_screen)
        demeter2_samples = list(pd.read_table(input.demeter2, index_col=0, nrows=0).columns)
        
        # generate unique drug id to avoid duplicates
        # as there are drugs screend with different concentrations
        # in both screens
        drug_response["ID"] = drug_response["DRUG_ID"].astype(str) + "_" +\
                              drug_response["MAX_CONC"].astype(str)
        
        # mark if cell line was also screened in Demeter2
        # (we want to train only with unseen cell lines)
        drug_response["in_demeter2"] = drug_response["ARXSPAN_ID"].isin(demeter2_samples)
        
        # GDSC1
        idx_train = (drug_response["DATASET"] == "GDSC1") & (~drug_response["in_demeter2"])
        idx_test = (drug_response["DATASET"] == "GDSC1") & (drug_response["in_demeter2"])
        drug_response.loc[idx_train].to_csv(output.gdsc1_train, **SAVE_KWS)
        drug_response.loc[idx_test].to_csv(output.gdsc1_test, **SAVE_KWS)
        
        # GDSC2
        idx_train = (drug_response["DATASET"] == "GDSC2") & (~drug_response["in_demeter2"])
        idx_test = (drug_response["DATASET"] == "GDSC2") & (drug_response["in_demeter2"])
        drug_response.loc[idx_train].to_csv(output.gdsc2_train, **SAVE_KWS)
        drug_response.loc[idx_test].to_csv(output.gdsc2_test, **SAVE_KWS)
        
        
rule preprocess_stringdb:
    input:
        ppi = os.path.join(RAW_DIR,'STRINGDB','9606.protein.links.full.v11.5.txt.gz'),
        aliases = os.path.join(RAW_DIR,'STRINGDB','9606.protein.aliases.v11.5.txt.gz')
    output:
        os.path.join(PREP_DIR,'ppi','STRINGDB.tsv.gz')
    shell:
        """
        python scripts/preprocess_stringdb.py \
                    --raw_ppi_file={input.ppi} \
                    --raw_aliases_file={input.aliases} \
                    --prep_ppi_file={output}
        """
        
        
rule preprocess_gdsc_targets:
    input:
        raw_drug_targets = os.path.join(RAW_DIR,'GDSC','screened_compunds_rel_8.2.csv'),
        symbol_checker = os.path.join(SUPPORT_DIR,'hgnc-symbol-check-drug_targets.csv')
    output:
        os.path.join(PREP_DIR,'drug_screens','drug_targets.tsv.gz')
    run:
        import pandas as pd
        raw_drug_targets = pd.read_csv(input.raw_drug_targets)
        corrector = pd.read_csv(input.symbol_checker, skiprows=1)
        
        # prep raw
        raw_drug_targets["TARGET"] = raw_drug_targets["TARGET"].str.replace(",",";")
        raw_drug_targets["DRUG_NAME"] = raw_drug_targets["DRUG_NAME"].str.upper()
        raw_drug_targets["ORIGIN"] = "GDSC"
        raw_drug_targets = raw_drug_targets.drop(columns="SCREENING_SITE")
        
        drug_targets = raw_drug_targets.copy()
        
        # prep corrector dictionary
        corrector = corrector[
            ["Input","Approved symbol"]
        ].dropna().drop_duplicates()
        corrector["symbol"] = corrector["Approved symbol"].str.split(";")
        corrector = corrector.explode("symbol")
        corrector["symbol"] = corrector["symbol"].str.replace(" ","")
        corrector = corrector.set_index("Input")["symbol"].to_dict()
        
        # pivot longer the target genes
        drug_targets["TARGET"] = drug_targets["TARGET"].str.split(";")
        drug_targets = drug_targets.explode("TARGET")
        drug_targets["TARGET"] = drug_targets["TARGET"].str.replace(" ", "")
        drug_targets["TARGET"] = [corrector[t] if t in corrector.keys() else t 
                                  for t in drug_targets["TARGET"]]
        
        # save
        drug_targets.to_csv(output[0], index=False, sep="\t", compression="gzip")
        
        print("Done!")
        
        
rule preprocess_Pietila2021:
    input:
        metadata = os.path.join(RAW_DIR,'articles','Pietila2021','metadata-EGAD00001006456-Pietila2021.tsv'),
        psi = os.path.join(RAW_DIR,'articles','Pietila2021','vast_out','PSI-minN_1-minSD_0-noVLOW-min_ALT_use25-Tidy.tab.gz'),
        genexpr = os.path.join(RAW_DIR,'articles','Pietila2021','vast_out','TPM-hg38-329.tab.gz')
    output:
        metadata = os.path.join(PREP_DIR,'metadata','Pietila2021.tsv.gz'),
        psi_EX = os.path.join(PREP_DIR,'event_psi','Pietila2021-EX.tsv.gz'),
        psi_ALTA = os.path.join(PREP_DIR,'event_psi','Pietila2021-ALTA.tsv.gz'),
        psi_ALTD = os.path.join(PREP_DIR,'event_psi','Pietila2021-ALTD.tsv.gz'),
        psi_INT = os.path.join(PREP_DIR,'event_psi','Pietila2021-INT.tsv.gz'),
        genexpr = os.path.join(PREP_DIR,'genexpr_tpm','Pietila2021.tsv.gz')
    run:
        import gc
        import pandas as pd
        import numpy as np
        
        # load
        print("Loading data...")
        metadata = pd.read_table(input.metadata)
        psi = pd.read_table(input.psi, index_col=0)
        genexpr = pd.read_table(input.genexpr, index_col=[0,1])
        
        gc.collect()
        
        # PSI
        print("Processing PSI matrix...")
        ## drop empty rows
        is_na = psi.isnull()
        non_missing = is_na.shape[1] - is_na.sum(1)
        to_keep = non_missing >= 1
        psi = psi.loc[to_keep]
        
        ## remove vast-tools' suffix
        psi.columns = [c.replace('_1','') for c in psi.columns]
        
        ## split by event type
        event_types = ["EX","ALTA","ALTD","INT"]
        psis = {e: psi.loc[psi.index.str.contains(e)] for e in event_types}        
        
        # TPM
        print("Processing TPM matrix...")
        ## remove vast-tools' suffix
        genexpr.columns = [c.replace('_1','') for c in genexpr.columns]
        
        # save
        print("Saving...")
        
        ## metadata
        metadata.to_csv(output.metadata, **SAVE_PARAMS)
        
        ## PSIs
        psis["EX"].reset_index().to_csv(output.psi_EX, **SAVE_PARAMS)
        psis["ALTD"].reset_index().to_csv(output.psi_ALTD, **SAVE_PARAMS)
        psis["ALTA"].reset_index().to_csv(output.psi_ALTA, **SAVE_PARAMS)
        psis["INT"].reset_index().to_csv(output.psi_INT, **SAVE_PARAMS)
        
        ## TPMs
        genexpr.reset_index().drop(columns='NAME').to_csv(output.genexpr, **SAVE_PARAMS)        
        
        print("Done!")